{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-08T18:29:16.466845Z",
     "iopub.status.busy": "2021-09-08T18:29:16.466425Z",
     "iopub.status.idle": "2021-09-08T18:29:27.705182Z",
     "shell.execute_reply": "2021-09-08T18:29:27.704132Z",
     "shell.execute_reply.started": "2021-09-08T18:29:16.466758Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting biosppy\n",
      "  Downloading biosppy-0.7.3.tar.gz (85 kB)\n",
      "\u001b[K     |████████████████████████████████| 85 kB 1.5 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting bidict\n",
      "  Downloading bidict-0.21.3-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from biosppy) (2.10.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from biosppy) (3.4.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from biosppy) (1.19.5)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from biosppy) (0.23.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from biosppy) (1.6.3)\n",
      "Requirement already satisfied: shortuuid in /opt/conda/lib/python3.7/site-packages (from biosppy) (1.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from biosppy) (1.15.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from biosppy) (1.0.1)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (from biosppy) (4.5.2.54)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->biosppy) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->biosppy) (8.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->biosppy) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->biosppy) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->biosppy) (0.10.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->biosppy) (2.1.0)\n",
      "Building wheels for collected packages: biosppy\n",
      "  Building wheel for biosppy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for biosppy: filename=biosppy-0.7.3-py2.py3-none-any.whl size=95409 sha256=cf13a2e640dad03ecc380a26b4a9c948e26c0e29d920d95a2a31a7ffe79a35bc\n",
      "  Stored in directory: /root/.cache/pip/wheels/2f/4f/8f/28b2adc462d7e37245507324f4817ce1c64ef2464f099f4f0b\n",
      "Successfully built biosppy\n",
      "Installing collected packages: bidict, biosppy\n",
      "Successfully installed bidict-0.21.3 biosppy-0.7.3\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install biosppy   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-08T18:29:27.707263Z",
     "iopub.status.busy": "2021-09-08T18:29:27.706977Z",
     "iopub.status.idle": "2021-09-08T18:29:35.032189Z",
     "shell.execute_reply": "2021-09-08T18:29:35.031076Z",
     "shell.execute_reply.started": "2021-09-08T18:29:27.707231Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import wfdb\n",
    "import os                                                                                                  \n",
    "import gc\n",
    "import scipy       \n",
    "import sklearn\n",
    "from pathlib import Path\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "from scipy.spatial import distance\n",
    "from biosppy.signals import ecg\n",
    "from scipy.interpolate import PchipInterpolator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-08T18:29:35.034080Z",
     "iopub.status.busy": "2021-09-08T18:29:35.033731Z",
     "iopub.status.idle": "2021-09-08T18:29:40.900958Z",
     "shell.execute_reply": "2021-09-08T18:29:40.900038Z",
     "shell.execute_reply.started": "2021-09-08T18:29:35.034045Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on TPU  ['10.0.0.2:8470']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
    "    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
    "except ValueError:\n",
    "    raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
    "\n",
    "tf.config.experimental_connect_to_cluster(tpu)\n",
    "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIT-BIH Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T03:16:06.818899Z",
     "iopub.status.busy": "2021-08-03T03:16:06.818503Z",
     "iopub.status.idle": "2021-08-03T03:16:06.839175Z",
     "shell.execute_reply": "2021-08-03T03:16:06.838124Z",
     "shell.execute_reply.started": "2021-08-03T03:16:06.818865Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "####### Dataset Creation  \n",
    "###### Reading Dataset\n",
    "\n",
    "##### Function to read a record from single dataset\n",
    "def data_read_mit(filepath):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to read the the inputs from MIT-BIH Dataset\n",
    "    INPUTS:- \n",
    "    1)filepath: Path to the csv file\n",
    "    \n",
    "    OUTPUTS:-\n",
    "    1)Output_signal: Output 1D array signal \n",
    "    \"\"\"\n",
    "    return (np.array(pd.read_csv(filepath,index_col=0).iloc[:,[0]]))   \n",
    "    \n",
    "##### Function to Required Annotations from .txt files\n",
    "def feature_extractor(txt_file_path):\n",
    "    \n",
    "    \"\"\"\n",
    "       Function to extract time series data \n",
    "       from a .txt file\n",
    "    \"\"\"\n",
    "    \n",
    "    #### Reading File\n",
    "    line_list = []\n",
    "\n",
    "    with open(txt_file_path, 'r') as reader:\n",
    "\n",
    "    # Read and print the entire file line by line\n",
    "        line = reader.readline()\n",
    "        while line != '':  # The EOF char is an empty string\n",
    "            #print(line, end='')\n",
    "            line_list.append(line)\n",
    "            line = reader.readline()\n",
    "    \n",
    "    #### Taking the Time Step Data\n",
    "    line_list = line_list[1:]\n",
    "    \n",
    "    #### Splitting the Collected Text Strings and Converting them into Floating type values\n",
    "    new_list = []\n",
    "\n",
    "    for item in line_list:\n",
    "        for idx,sub_item in enumerate(item.split()):\n",
    "            if(idx == 1):\n",
    "                new_list.append(int(sub_item))\n",
    "                break\n",
    "    \n",
    "    ### Returning the feature extracted list as numpy array\n",
    "    return np.array(new_list)\n",
    "\n",
    "###### Function to Segment Signals\n",
    "##### Constants\n",
    "FS = 500\n",
    "W_LEN = 256\n",
    "W_LEN_1_4 = 256 // 4\n",
    "W_LEN_3_4 = 3 * (256 // 4)\n",
    "\n",
    "##### Function\n",
    "def segmentSignals(signal, r_peaks_annot, normalization=True, person_id= None, file_id=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Segments signals based on the detected R-Peak\n",
    "    Args:\n",
    "        signal (numpy array): input signal\n",
    "        r_peaks_annot (int []): r-peak locations.\n",
    "        normalization (bool, optional): apply z-normalization or not? . Defaults to True.\n",
    "        person_id ([type], optional): [description]. Defaults to None.\n",
    "        file_id ([type], optional): [description]. Defaults to None.\n",
    "    Returns:\n",
    "            [tuple(numpy array,numpy array)]: segmented signals and refined r-peaks\n",
    "    \"\"\"\n",
    "    def refine_rpeaks(signal, r_peaks):\n",
    "        \"\"\"\n",
    "        Refines the detected R-peaks. If the R-peak is slightly shifted, this assigns the \n",
    "        highest point R-peak.\n",
    "        Args:\n",
    "            signal (numpy array): input signal\n",
    "            r_peaks (int []): list of detected r-peaks\n",
    "        Returns:\n",
    "            [numpy array]: refined r-peaks\n",
    "        \"\"\"\n",
    "\n",
    "        r_peaks2 = np.array(r_peaks)            # make a copy\n",
    "        for i in range(len(r_peaks)):\n",
    "            r = r_peaks[i]          # current R-peak\n",
    "            small_segment = signal[max(0,r-100):min(len(signal),r+100)]         # consider the neighboring segment of R-peak\n",
    "            r_peaks2[i] = np.argmax(small_segment) - 100 + r_peaks[i]           # picking the highest point\n",
    "            r_peaks2[i] = min(r_peaks2[i],len(signal))                          # the detected R-peak shouldn't be outside the signal\n",
    "            r_peaks2[i] = max(r_peaks2[i],0)                                    # checking if it goes before zero    \n",
    "        return r_peaks2                     # returning the refined r-peak list\n",
    "    \n",
    "    segmented_signals = []                      # array containing the segmented beats\n",
    "    \n",
    "    r_peaks = np.array(r_peaks_annot)\n",
    "    r_peaks = refine_rpeaks(signal, r_peaks)\n",
    "    skip_len = 5 # Parameter to specify number of r_peaks in one signal\n",
    "    max_seq_len = 1280 # Parameter to specify maximum sequence length\n",
    "    \n",
    "    for r_curr in range(0,int(r_peaks.shape[0]-(skip_len-1)),skip_len):\n",
    "        if ((r_peaks[r_curr]-W_LEN_1_4)<0) or ((r_peaks[r_curr+(skip_len-1)]+W_LEN_3_4)>=len(signal)):           # not enough signal to segment\n",
    "            continue\n",
    "        segmented_signal = np.array(signal[r_peaks[r_curr]-W_LEN_1_4:r_peaks[r_curr+(skip_len-1)]+W_LEN_3_4])        # segmenting a heartbeat\n",
    "        segmented_signal = list(segmented_signal)\n",
    "        #print(segmented_signal.shape)\n",
    "        \n",
    "        if(len(segmented_signal) < 1280):\n",
    "            for m in range(int(1280-len(segmented_signal))): # Zero Padding\n",
    "                segmented_signal.append(0)\n",
    "        else:\n",
    "            segmented_signal = (segmented_signal[:int(max_seq_len)])\n",
    "            \n",
    "        segmented_signal = np.array(segmented_signal)\n",
    "        \n",
    "        if(segmented_signal.shape != (1280,1)):    \n",
    "            segmented_signal = np.reshape(segmented_signal,(1280,1))\n",
    "            \n",
    "        if (normalization):             # Z-score normalization\n",
    "            if abs(np.std(segmented_signal))<1e-6:          # flat line ECG, will cause zero division error\n",
    "                continue\n",
    "            segmented_signal = (segmented_signal - np.mean(segmented_signal)) / np.std(segmented_signal)            \n",
    "              \n",
    "        #if not np.isnan(segmented_signal).any():                    # checking for nan, this will never happen\n",
    "            segmented_signals.append(segmented_signal)\n",
    "\n",
    "    return segmented_signals,r_peaks           # returning the segmented signals and the refined r-peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T03:16:17.440246Z",
     "iopub.status.busy": "2021-08-03T03:16:17.439855Z",
     "iopub.status.idle": "2021-08-03T03:21:24.358227Z",
     "shell.execute_reply": "2021-08-03T03:21:24.356973Z",
     "shell.execute_reply.started": "2021-08-03T03:16:17.440212Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "###### Looping for Reading the Entire Dataset - OpenSet Testing\n",
    "\n",
    "! mkdir './5_Beat_Ecg_MITBIH_1' # Generating major database of datasets\n",
    "current_index = 1\n",
    "\n",
    "mit_dbs_path = '../input/mitbih-database'\n",
    "for i in range(0,96,2): # Loop over all the files\n",
    "    print(i)\n",
    "    print(np.sort(os.listdir(mit_dbs_path))[i])\n",
    "    rec_file_path = os.path.join(mit_dbs_path,str(np.sort(os.listdir(mit_dbs_path))[i])) # Path Selection\n",
    "    attr_file_path = os.path.join(mit_dbs_path,str(np.sort(os.listdir(mit_dbs_path))[i+1])) # Path Selction\n",
    "    \n",
    "    signal_current = data_read_mit(rec_file_path) # Current ECG Signal\n",
    "    r_peaks_current = feature_extractor(attr_file_path) # R-peaks\n",
    "    seg_signal_current,new_r_peaks = (segmentSignals(signal_current,list(r_peaks_current))) # Segmented ECG Signals\n",
    "    #seg_signal_current = np.array(seg_signal_current)\n",
    "    #print(seg_signal_current.shape[0])\n",
    "    \n",
    "    if(i == 48):\n",
    "        current_index = current_index-1\n",
    "        current_storage_path = './5_Beat_Ecg_MITBIH_1'+'/person'+str(current_index)\n",
    "        #Path(current_storage_path).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "        for j in range(len(seg_signal_current)):\n",
    "            file_name_current = current_storage_path+'/Extra'+str(j)\n",
    "            np.savez_compressed(file_name_current,seg_signal_current[j])\n",
    "            \n",
    "        current_index = current_index+1\n",
    "    \n",
    "    else:\n",
    "        current_storage_path = './5_Beat_Ecg_MITBIH_1'+'/person'+str(current_index)\n",
    "        Path(current_storage_path).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "        for j in range(len(seg_signal_current)):\n",
    "            file_name_current = current_storage_path+'/'+str(j)\n",
    "            np.savez_compressed(file_name_current,seg_signal_current[j])\n",
    "            \n",
    "        current_index = current_index+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T03:32:10.309813Z",
     "iopub.status.busy": "2021-08-03T03:32:10.308813Z",
     "iopub.status.idle": "2021-08-03T03:33:17.417475Z",
     "shell.execute_reply": "2021-08-03T03:33:17.4161Z",
     "shell.execute_reply.started": "2021-08-03T03:32:10.309753Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "###### Creation of Numpy Arrays\n",
    "##### Defining Essentials\n",
    "data_folder = './5_Beat_Ecg_MITBIH_1'\n",
    "X_train = []\n",
    "X_dev = []\n",
    "y_train = []     \n",
    "y_dev = []\n",
    "\n",
    "##### Looping Over to populate the dataset\n",
    "for index,sub_data_folder in enumerate(np.sort(os.listdir(data_folder))):\n",
    "    sub_data_folder_path = os.path.join(data_folder,sub_data_folder)\n",
    "    \n",
    "    #if(index <= 33):\n",
    "          \n",
    "    for idx,item in enumerate(np.sort(os.listdir(sub_data_folder_path))): # Looping Over a person's folder\n",
    "        item_path = os.path.join(sub_data_folder_path,item)\n",
    "\n",
    "        #### Train on Past Test on Present (TPTP)\n",
    "        if(idx <= int(np.round(len(os.listdir(sub_data_folder_path))))):\n",
    "            X_train.append(np.load(item_path,allow_pickle=True)['arr_0'])\n",
    "            y_train.append(index+89) # Setting the Value of class label after 89 examples of ECG1D Dataset for CD_EMP\n",
    "            \n",
    "    print('Person'+' '+str(index+1)+'s data taken')\n",
    "    \n",
    "##### Creation of Numpy Arrays\n",
    "X_train_CD_train_MITBIH = np.array(X_train)\n",
    "y_train_CD_train_MITBIH = np.array(y_train)\n",
    "\n",
    "##### Testing arrays\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "print(np.max(y_train))\n",
    "print(np.min(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PTB Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T05:04:27.328691Z",
     "iopub.status.busy": "2021-08-03T05:04:27.328231Z",
     "iopub.status.idle": "2021-08-03T05:04:27.357273Z",
     "shell.execute_reply": "2021-08-03T05:04:27.356035Z",
     "shell.execute_reply.started": "2021-08-03T05:04:27.328651Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "###### Constants\n",
    "FS = 360\n",
    "W_LEN = 256\n",
    "W_LEN_1_4 = 256 // 4\n",
    "W_LEN_3_4 = 3 * (256 // 4)\n",
    "\n",
    "###### Function to Segment Signals\n",
    "\n",
    "def segmentSignals(signal, r_peaks_annot, normalization=True, person_id= None, file_id=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Segments signals based on the detected R-Peak\n",
    "    Args:\n",
    "        signal (numpy array): input signal\n",
    "        r_peaks_annot (int []): r-peak locations.\n",
    "        normalization (bool, optional): apply z-normalization or not? . Defaults to True.\n",
    "        person_id ([type], optional): [description]. Defaults to None.\n",
    "        file_id ([type], optional): [description]. Defaults to None.\n",
    "    Returns:\n",
    "            [tuple(numpy array,numpy array)]: segmented signals and refined r-peaks\n",
    "    \"\"\"\n",
    "    def refine_rpeaks(signal, r_peaks):\n",
    "        \"\"\"\n",
    "        Refines the detected R-peaks. If the R-peak is slightly shifted, this assigns the \n",
    "        highest point R-peak.\n",
    "        Args:\n",
    "            signal (numpy array): input signal\n",
    "            r_peaks (int []): list of detected r-peaks\n",
    "        Returns:\n",
    "            [numpy array]: refined r-peaks\n",
    "        \"\"\"\n",
    "        r_peaks2 = np.array(r_peaks)            # make a copy\n",
    "        for i in range(len(r_peaks)):\n",
    "            r = r_peaks[i]          # current R-peak\n",
    "            small_segment = signal[max(0,r-100):min(len(signal),r+100)]         # consider the neighboring segment of R-peak\n",
    "            r_peaks2[i] = np.argmax(small_segment) - 100 + r_peaks[i]           # picking the highest point\n",
    "            r_peaks2[i] = min(r_peaks2[i],len(signal))                          # the detected R-peak shouldn't be outside the signal\n",
    "            r_peaks2[i] = max(r_peaks2[i],0)                                    # checking if it goes before zero    \n",
    "        return r_peaks2                     # returning the refined r-peak list\n",
    "    \n",
    "    segmented_signals = []                      # array containing the segmented beats\n",
    "    \n",
    "    r_peaks = np.array(r_peaks_annot)\n",
    "\n",
    "    r_peaks = refine_rpeaks(signal, r_peaks)\n",
    "    skip_len = 5 # Parameter to specify number of r_peaks in one signal\n",
    "    max_seq_len = 1280 # Parameter to specify maximum sequence length\n",
    "    \n",
    "    for r_curr in range(0,int(r_peaks.shape[0]-(skip_len-1)),skip_len):\n",
    "        if ((r_peaks[r_curr]-W_LEN_1_4)<0) or ((r_peaks[r_curr+(skip_len-1)]+W_LEN_3_4)>=len(signal)):           # not enough signal to segment\n",
    "            continue\n",
    "        segmented_signal = np.array(signal[r_peaks[r_curr]-W_LEN_1_4:r_peaks[r_curr+(skip_len-1)]+W_LEN_3_4])        # segmenting a heartbeat\n",
    "        segmented_signal = list(segmented_signal)\n",
    "        #print(segmented_signal.shape)\n",
    "        \n",
    "        if(len(segmented_signal) < 1280):\n",
    "            for m in range(int(1280-len(segmented_signal))): # Zero Padding\n",
    "                segmented_signal.append(0)\n",
    "        else:\n",
    "            segmented_signal = (segmented_signal[:int(max_seq_len)])\n",
    "            \n",
    "        segmented_signal = np.array(segmented_signal)\n",
    "        \n",
    "        if(segmented_signal.shape != (1280,1)):    \n",
    "            segmented_signal = np.reshape(segmented_signal,(1280,1))\n",
    "            \n",
    "        if (normalization):             # Z-score normalization\n",
    "            if abs(np.std(segmented_signal))<1e-6:          # flat line ECG, will cause zero division error\n",
    "                continue\n",
    "            segmented_signal = (segmented_signal - np.mean(segmented_signal)) / np.std(segmented_signal)            \n",
    "              \n",
    "        #if not np.isnan(segmented_signal).any():                    # checking for nan, this will never happen\n",
    "            segmented_signals.append(segmented_signal)\n",
    "\n",
    "    return segmented_signals,r_peaks           # returning the segmented signals and the refined r-peaks\n",
    "\n",
    "###### Function to Read Records\n",
    "\n",
    "def read_rec(rec_path):\n",
    "\n",
    "    \"\"\" \n",
    "    Function to read record and return Segmented Signals\n",
    "\n",
    "    INPUTS:-\n",
    "    1) rec_path : Path of the Record\n",
    "\n",
    "    OUTPUTS:-\n",
    "    1) seg_sigs : Final Segmented Signals\n",
    "\n",
    "    \"\"\"\n",
    "    number_of_peaks = 5 # For extracting the required number of peaks                                    \n",
    "    full_rec = (wfdb.rdrecord(rec_path)).p_signal[:,0] # Entire Record - Taking Signal from Lead-1\n",
    "\n",
    "    f = PchipInterpolator(np.arange(int(full_rec.shape[0])),full_rec) # Fitting Interpolation Function\n",
    "    num_samples = int(full_rec.shape[0]) # Total Samples in 1000Hz Signal\n",
    "    num_samples_final = int(num_samples*(360/1000))\n",
    "    x_samp = (np.arange(num_samples)*(1000/360))[:num_samples_final] # Fixing Interpolation Input Values\n",
    "    full_rec_interp = f(x_samp)  # Intepolating Values \n",
    "    \n",
    "    r_peaks_init = ecg.hamilton_segmenter(full_rec_interp,360)[0] # R-Peak Segmentation and input is the signal frequency of 500Hz in this case\n",
    "    final_peak_index = r_peaks_init[int(r_peaks_init.shape[0] - int((r_peaks_init.shape[0]%number_of_peaks)))-1]\n",
    "    r_peaks_final = r_peaks_init[:final_peak_index] # Final Number of R_Peaks\n",
    "    full_rec_final = full_rec_interp[:int(r_peaks_final[-1]+W_LEN)] # Final Sequence\n",
    "    seg_sigs, r_peaks_ref = segmentSignals(full_rec_final,list(r_peaks_final)) # Final Signal Segmentation\n",
    "\n",
    "    return seg_sigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T05:04:40.001005Z",
     "iopub.status.busy": "2021-08-03T05:04:40.000604Z",
     "iopub.status.idle": "2021-08-03T05:04:42.543974Z",
     "shell.execute_reply": "2021-08-03T05:04:42.542898Z",
     "shell.execute_reply.started": "2021-08-03T05:04:40.000974Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "###### Extracting List of the Elements with Two Sessions \n",
    "dir = '../input/ptb-dataset/ptb-diagnostic-ecg-database-1.0.0'\n",
    "total_index = 0\n",
    "#subjects_with_two = []\n",
    "subjects = []\n",
    "\n",
    "for item in np.sort(os.listdir(dir)):\n",
    "    #print('----------------------------------')\n",
    "    #print(item)\n",
    "    dir_sub = os.path.join(dir,item)\n",
    "    if(os.path.isdir(dir_sub)):\n",
    "        #ubjects.append(item)\n",
    "        #print(len(os.listdir(dir_sub))//3)\n",
    "        if(len(os.listdir(dir_sub))//3 >= 2):\n",
    "            subjects.append(item)\n",
    "            #total_index = total_index+1   \n",
    "            #print(item)\n",
    "        #    subjects_with_two.append(item)\n",
    "    #print('----------------------------------')\n",
    "\n",
    "#print(total_index)\n",
    "#print(subjects_with_two)\n",
    "\n",
    "#subjects = shuffle(subjects)[:100] # Shuffling and Taking 100 Subjects \n",
    "#print(subjects)\n",
    "\n",
    "print(subjects)\n",
    "print(len(subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T05:04:56.480722Z",
     "iopub.status.busy": "2021-08-03T05:04:56.480299Z",
     "iopub.status.idle": "2021-08-03T05:06:49.003348Z",
     "shell.execute_reply": "2021-08-03T05:06:49.001863Z",
     "shell.execute_reply.started": "2021-08-03T05:04:56.480674Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "###### Creation of Numpy Arrays \n",
    "main_dir = '../input/ptb-dataset/ptb-diagnostic-ecg-database-1.0.0'\n",
    "\n",
    "X_train = []\n",
    "X_dev = []\n",
    "y_train = []\n",
    "y_dev = []\n",
    "\n",
    "current_index = 0\n",
    "\n",
    "#for person_index,person_folder in enumerate(list(np.sort(os.listdir(main_dir)))):\n",
    " \n",
    "for person_folder in np.sort(subjects):\n",
    "    \n",
    "    #if(current_index <= 231): # Taking 80% of the subjects for training \n",
    "    \n",
    "    person_folder_path = os.path.join(main_dir,person_folder)\n",
    "    person_folder_items = (list(np.sort(os.listdir(person_folder_path))))\n",
    "\n",
    "    for file_idx in range(0,len(person_folder_items),3):\n",
    "        file_path_list = str((os.path.join(person_folder_path,person_folder_items[file_idx])))\n",
    "        file_num = file_idx//3\n",
    "\n",
    "        rec_path = ''\n",
    "        for item_index in range(0,(len(file_path_list)-4)):\n",
    "            rec_path = rec_path+str(file_path_list[item_index])\n",
    "\n",
    "        seg_signal_current = read_rec(rec_path) # Extracting Records\n",
    "\n",
    "        # Division across Time\n",
    "        #for k in range(len(seg_signal_current)):\n",
    "\n",
    "        #    if(k <= np.round(len(seg_signal_current)*0.5)):\n",
    "        #        X_train.append(seg_signal_current[k])\n",
    "        #        y_train.append(current_index)\n",
    "\n",
    "        #    else:\n",
    "        #        X_dev.append(seg_signal_current[k])\n",
    "        #        y_dev.append(current_index)\n",
    "\n",
    "        if(file_num == 0):\n",
    "            for k in range(len(seg_signal_current)):\n",
    "                X_train.append(seg_signal_current[k])\n",
    "                y_train.append(current_index)\n",
    "                \n",
    "        if(file_num == 1):\n",
    "            for k in range(len(seg_signal_current)):\n",
    "                X_dev.append(seg_signal_current[k])\n",
    "                y_dev.append(current_index)\n",
    "\n",
    "    current_index = current_index+1\n",
    "    print('Processed for Person - '+str(current_index))\n",
    "\n",
    "##### Creation of Numpy Arrays\n",
    "print(np.array(X_train).shape)\n",
    "print(np.array(y_train).shape)\n",
    "print(np.array(X_dev).shape)\n",
    "print(np.array(y_dev).shape)\n",
    "\n",
    "print(np.max(y_train))\n",
    "print(np.min(y_train))\n",
    "\n",
    "##### Shuffling Arrays\n",
    "X_train,y_train = shuffle(X_train,y_train)\n",
    "X_dev,y_dev = shuffle(X_dev,y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECG-1D Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T03:13:42.564986Z",
     "iopub.status.busy": "2021-08-03T03:13:42.564618Z",
     "iopub.status.idle": "2021-08-03T03:13:42.588644Z",
     "shell.execute_reply": "2021-08-03T03:13:42.587443Z",
     "shell.execute_reply.started": "2021-08-03T03:13:42.564951Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "####### Dataset Creation \n",
    "\n",
    "###### Constants\n",
    "FS = 360\n",
    "W_LEN = 256\n",
    "W_LEN_1_4 = 256 // 4\n",
    "W_LEN_3_4 = 3 * (256 // 4)\n",
    "\n",
    "###### Function to Read a Record\n",
    "def read_rec(rec_path):\n",
    "\n",
    "    \"\"\" \n",
    "    Function to read record and return Segmented Signals\n",
    "\n",
    "    INPUTS:-\n",
    "    1) rec_path : Path of the Record\n",
    "\n",
    "    OUTPUTS:-\n",
    "    1) seg_sigs : Final Segmented Signals\n",
    "\n",
    "    \"\"\"\n",
    "    number_of_peaks = 2 # For extracting the required number of peaks                                    \n",
    "    full_rec = (wfdb.rdrecord(rec_path)).p_signal[:,1] # Entire Record\n",
    "\n",
    "    f = PchipInterpolator(np.arange(10000),full_rec) # Fitting Interpolation Function\n",
    "    x_samp = (np.arange(10000)*(500/360))[:7200] # Fixing Interpolation Input Values\n",
    "    full_rec_interp = f(x_samp)  # Intepolating Values \n",
    "    r_peaks_init = ecg.hamilton_segmenter(full_rec_interp,360)[0] # R-Peak Segmentation and input is the signal frequency of 500Hz in this case\n",
    "    final_peak_index = r_peaks_init[int(r_peaks_init.shape[0] - int((r_peaks_init.shape[0]%number_of_peaks)))-1]\n",
    "    r_peaks_final = r_peaks_init[:final_peak_index] # Final Number of R_Peaks\n",
    "    full_rec_final = full_rec_interp[:int(r_peaks_final[-1]+W_LEN)] # Final Sequence\n",
    "    seg_sigs, r_peaks_ref = segmentSignals(full_rec_final,list(r_peaks_final)) # Final Signal Segmentation\n",
    "\n",
    "    return seg_sigs # Returning the Ouput of the Signal Segmentation\n",
    "\n",
    "###### Function to Segment Signals\n",
    "\n",
    "##### Function\n",
    "def segmentSignals(signal, r_peaks_annot, normalization=True, person_id= None, file_id=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Segments signals based on the detected R-Peak\n",
    "    Args:\n",
    "        signal (numpy array): input signal\n",
    "        r_peaks_annot (int []): r-peak locations.\n",
    "        normalization (bool, optional): apply z-normalization or not? . Defaults to True.\n",
    "        person_id ([type], optional): [description]. Defaults to None.\n",
    "        file_id ([type], optional): [description]. Defaults to None.\n",
    "    Returns:\n",
    "            [tuple(numpy array,numpy array)]: segmented signals and refined r-peaks\n",
    "    \"\"\"\n",
    "    def refine_rpeaks(signal, r_peaks):\n",
    "        \"\"\"\n",
    "        Refines the detected R-peaks. If the R-peak is slightly shifted, this assigns the \n",
    "        highest point R-peak.\n",
    "        Args:\n",
    "            signal (numpy array): input signal\n",
    "            r_peaks (int []): list of detected r-peaks\n",
    "        Returns:\n",
    "            [numpy array]: refined r-peaks\n",
    "        \"\"\"\n",
    "        r_peaks2 = np.array(r_peaks)            # make a copy\n",
    "        for i in range(len(r_peaks)):\n",
    "            r = r_peaks[i]          # current R-peak\n",
    "            small_segment = signal[max(0,r-100):min(len(signal),r+100)]         # consider the neighboring segment of R-peak\n",
    "            r_peaks2[i] = np.argmax(small_segment) - 100 + r_peaks[i]           # picking the highest point\n",
    "            r_peaks2[i] = min(r_peaks2[i],len(signal))                          # the detected R-peak shouldn't be outside the signal\n",
    "            r_peaks2[i] = max(r_peaks2[i],0)                                    # checking if it goes before zero    \n",
    "        return r_peaks2                     # returning the refined r-peak list\n",
    "    \n",
    "    segmented_signals = []                      # array containing the segmented beats\n",
    "    \n",
    "    r_peaks = np.array(r_peaks_annot)\n",
    "\n",
    "    r_peaks = refine_rpeaks(signal, r_peaks)\n",
    "    skip_len = 5 # Parameter to specify number of r_peaks in one signal\n",
    "    max_seq_len = 1280 # Parameter to specify maximum sequence length\n",
    "    \n",
    "    for r_curr in range(0,int(r_peaks.shape[0]-(skip_len-1)),skip_len):\n",
    "        if ((r_peaks[r_curr]-W_LEN_1_4)<0) or ((r_peaks[r_curr+(skip_len-1)]+W_LEN_3_4)>=len(signal)):           # not enough signal to segment\n",
    "            continue\n",
    "        segmented_signal = np.array(signal[r_peaks[r_curr]-W_LEN_1_4:r_peaks[r_curr+(skip_len-1)]+W_LEN_3_4])        # segmenting a heartbeat\n",
    "        segmented_signal = list(segmented_signal)\n",
    "        #print(segmented_signal.shape)\n",
    "        \n",
    "        if(len(segmented_signal) < 1280):\n",
    "            for m in range(int(1280-len(segmented_signal))): # Zero Padding\n",
    "                segmented_signal.append(0)\n",
    "        else:\n",
    "            segmented_signal = (segmented_signal[:int(max_seq_len)])\n",
    "            \n",
    "        segmented_signal = np.array(segmented_signal)\n",
    "        \n",
    "        if(segmented_signal.shape != (1280,1)):    \n",
    "            segmented_signal = np.reshape(segmented_signal,(1280,1))\n",
    "            \n",
    "        if (normalization):             # Z-score normalization\n",
    "            if abs(np.std(segmented_signal))<1e-6:          # flat line ECG, will cause zero division error\n",
    "                continue\n",
    "            segmented_signal = (segmented_signal - np.mean(segmented_signal)) / np.std(segmented_signal)            \n",
    "              \n",
    "        #if not np.isnan(segmented_signal).any():                    # checking for nan, this will never happen\n",
    "            segmented_signals.append(segmented_signal)\n",
    "\n",
    "    return segmented_signals,r_peaks           # returning the segmented signals and the refined r-peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T03:14:09.107794Z",
     "iopub.status.busy": "2021-08-03T03:14:09.107301Z",
     "iopub.status.idle": "2021-08-03T03:14:14.388937Z",
     "shell.execute_reply": "2021-08-03T03:14:14.387608Z",
     "shell.execute_reply.started": "2021-08-03T03:14:09.107765Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "###### Numpy Array Creation \n",
    "path_to_dir = '../input/ecg1d/ecg-id-database-1.0.0'\n",
    "total_folders = 90\n",
    "current_index = 0\n",
    "\n",
    "X_train = []\n",
    "X_dev = []\n",
    "y_train = []\n",
    "y_dev = []\n",
    "\n",
    "#for item in subjects_with_two:\n",
    "for i in range(2,92):\n",
    "\n",
    "    if(i != 75):\n",
    "\n",
    "        print(i-1)\n",
    "        folder_path = os.path.join(path_to_dir,np.sort(os.listdir(path_to_dir))[i]) # Path Selection\n",
    "        #items_in_folder = int(len(folder_path)//3)\n",
    "        #current_storage_path = './5_Beat_Ecg_ECG1D'+'/person'+str(current_index)\n",
    "\n",
    "        #for j in os.listdir(item):\n",
    "\n",
    "        for j in range(2):\n",
    "\n",
    "            rec_path = folder_path+'/'+'rec'+'_'+str(j+1) # Path to Record\n",
    "            seg_signal_current = read_rec(rec_path)\n",
    "\n",
    "            if(j == 0):\n",
    "                for k in range(len(seg_signal_current)):\n",
    "                    #file_name_current = current_storage_path+'/'+str(j)+'_/'+str(k)\n",
    "                    #np.savez_compressed(file_name_current,seg_signal_current[k])\n",
    "                    X_train.append(seg_signal_current[k])\n",
    "                    y_train.append(current_index)\n",
    "\n",
    "            if(j == 1):\n",
    "                for k in range(len(seg_signal_current)):\n",
    "                    #file_name_current = current_storage_path+'/'+str(j)+'_/'+str(k)\n",
    "                    #np.savez_compressed(file_name_current,seg_signal_current[k])\n",
    "                    X_train.append(seg_signal_current[k])\n",
    "                    y_train.append(current_index)\n",
    "\n",
    "        current_index = current_index+1\n",
    "\n",
    "###### Creation of Numpy Arrays\n",
    "X_train_CD_train_ECG1D = np.array(X_train)\n",
    "y_train_CD_train_ECG1D = np.array(y_train)\n",
    "\n",
    "###### Checking Shape of the Arrays\n",
    "print(np.array(X_train).shape)\n",
    "print(np.array(y_train).shape)\n",
    "\n",
    "print(np.max(y_train))\n",
    "print(np.min(y_train))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
